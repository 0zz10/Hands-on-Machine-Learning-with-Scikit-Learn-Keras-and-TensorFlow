---

title: Chapter 8. Dimensionality Reduction
keywords: fastai
sidebar: home_sidebar


---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 08.Dim_Reduction.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
    
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Many ML problems will involve thousands or even millions of features per instance.</li>
<li>Not only all of these features make training extremly slow, but they can also make it much harder for an optimization method to find a good solution.</li>
<li>This problem is often referred to as the <strong>curse of dimensionality</strong>.</li>
<li>In real world problem, it is often possible to reduce the number of features considerably.<ul>
<li>Turning an intractable problem into a tractable one.</li>
</ul>
</li>
<li>The goal is to remove the maximum number of features while minimizing information loss that relates to a specific task<ul>
<li>Task example â€” Classifying MNIST digits.</li>
</ul>
</li>
<li>Reducing dimensionality does cause some information loss.</li>
<li>It also makes your pipeline a bit more complex and thus harder to maintain.</li>
<li>Dimensionality reduction is usually conducted to <strong>speed up training</strong>.</li>
<li>Dimensionality reduction is also extremly useful for data visualization.<ul>
<li>Taking it down to 2/3 dimensions for your data set will allow you visualize it in a 2/3D space.</li>
</ul>
</li>
<li>DataViz is also important to communicate your findings to people who are not data scientists.<ul>
<li>In Particular, decision makers who will use your results.</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>In this chapter we will:<ul>
<li>Discuss the curse of dimenstionality.</li>
<li>Get a sense of what goes on in a high-dimenstional space.</li>
<li>Consider the main two approaches to dimensionality reduction:<ul>
<li>Projection</li>
<li>Manifold Learning</li>
</ul>
</li>
<li>Go through 3 popular dimensionality reduction techniques:<ul>
<li>PCA</li>
<li>Kernel PCA</li>
<li>LLE</li>
</ul>
</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-Curse-of-Dimensionality">The Curse of Dimensionality<a class="anchor-link" href="#The-Curse-of-Dimensionality">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>We are so used to living in three dimensions<ul>
<li>4 if you consider time, and a few more if you are a string theorist.</li>
</ul>
</li>
<li>It turns out that many things behave very differently in high-dimensional spaces.</li>
<li>If you pick a random point in a unit square, it will have ~0.4% chance of being located at &lt;0.001 from a border.</li>
<li>But in a 1,000-dimensional hyper-cube the probability is &gt;99.999999%.<ul>
<li>Most points in a high-dimensional space are very close to the border.</li>
</ul>
</li>
<li>Same goes to distances betweeen points, If you pick two random points in a lower dimensional space, they will be closer in comparison to picking them from a high-dimensional space.</li>
<li><strong>There is just plenty of space in a high-dimensional one!</strong></li>
<li>High-dimensional datasets are at risk of being too sparse.</li>
<li>The most dimensions a dataset has, the more risk it is to overfit it.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Main-Approaches-to-Dimensionality-Reduction">Main Approaches to Dimensionality Reduction<a class="anchor-link" href="#Main-Approaches-to-Dimensionality-Reduction">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Projection">Projection<a class="anchor-link" href="#Projection">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include image.html style="width:50%" file="static/imgs/subspace_projection.png" %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Manifold-Learning">Manifold Learning<a class="anchor-link" href="#Manifold-Learning">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include image.html style="width:50%" file="static/imgs/manifold_classification.png" %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="PCA">PCA<a class="anchor-link" href="#PCA">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Principal Component Analysis is by far the most popular dimensionality reduction algorithm.</li>
<li>First, <strong>It identifies the hyperplane that lies closest to the data</strong>.</li>
<li>Then, <strong>It projects the data into it</strong>.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Preserving-the-Variance">Preserving the Variance<a class="anchor-link" href="#Preserving-the-Variance">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include image.html style="width:66%" file="static/imgs/2D_variance_projection.png" %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Principle-Components">Principle Components<a class="anchor-link" href="#Principle-Components">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>PCA identifies the axis that accounts for the largest amount of variance in the training set.</li>
<li>It also finds a second axis, orthogonal to the first one, that accounts for the largest amount of remaining variance.</li>
<li>If we're considering a higher-dimensional dataset, PCA would also find a third axis, and a fourth, and a fifth, and so on...<ul>
<li>As many axes as the number of dimensions in the dataset.</li>
</ul>
</li>
<li>The ith axis is called the ith <strong>principal component</strong> of the data.</li>
<li>So how can you find the principal components of a training set?</li>
<li>There is a standard matrix vectorization technique called <em>Singular Value Decomposition (SVD)</em><ul>
<li>It can decompose the training set $X$ into $X=U \Sigma V^T$</li>
<li>$V$ contains the unit vectors that define all the principal components that we are looking for:</li>
</ul>
</li>
</ul>
$$V=
  \begin{pmatrix}
    \vert &amp; \vert &amp; \dots &amp; \vert \\
    c_1 &amp; c_2 &amp; \dots &amp; c_n \\
    \vert &amp; \vert &amp; \dots &amp; \vert \\
  \end{pmatrix}
$$<ul>
<li>let's extract the principal components of a dataset using numpy's <code>svd</code> implementation:</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Let's start by generating some data:</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">sklearn</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">start</span><span class="o">=-</span><span class="mf">1.</span><span class="p">,</span> <span class="n">stop</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">X</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span><span class="o">/</span><span class="mf">7.</span>
<span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>((100,), (100,))</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;$X_1$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;$X_2$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">X</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(100, 2)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_centered</span> <span class="o">=</span> <span class="n">X</span> <span class="o">-</span> <span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">U</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">Vt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="n">X_centered</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">c1</span> <span class="o">=</span> <span class="n">Vt</span><span class="o">.</span><span class="n">T</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">c2</span> <span class="o">=</span> <span class="n">Vt</span><span class="o">.</span><span class="n">T</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">c1</span><span class="p">,</span> <span class="n">c2</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(array([0.70338697, 0.71080712]), array([ 0.71080712, -0.70338697]))</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>These two 2D points represent the unit vector points (origin at (0,0)) corresponding to the 2 principal components (axes that preserve variance).</li>
<li>PCA assumes that the dataset is centered around the origin, but scikit-learn implementation takes care of centering the data for you.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Projecting-down-to-$d$-Dimensions">Projecting down to $d$ Dimensions<a class="anchor-link" href="#Projecting-down-to-$d$-Dimensions">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Once you have identified all the principal components, you can reduce the dimensionality of the dataset down to $d$ dimensions by projecting it onto the hyperplane defined by the first $d$ principal components.</li>
<li>Selecting this hyperplane ensures that the projection will preserve as much variance as possible.</li>
<li>To Project the training set into the hyperplane and obtain a reduced dataset $X_{d-proj}$ of dimensionality $d$:<ul>
<li>Compute the matrix multiplication of the training set matrix $X$ by the matrix $W_{d}$ <ul>
<li>$W_{d}$ is the matrix containing the first $d$ columns of $V$ representing the principal components.</li>
</ul>
</li>
</ul>
</li>
</ul>
$$X_{d-proj}=XW_d$$<ul>
<li>Let's do it in Python:</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">W2</span> <span class="o">=</span> <span class="n">Vt</span><span class="o">.</span><span class="n">T</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X2D</span> <span class="o">=</span> <span class="n">X_centered</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W2</span><span class="p">)</span>
<span class="n">X2D</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(100, 2)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Using-Scikit-Learn">Using Scikit-Learn<a class="anchor-link" href="#Using-Scikit-Learn">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X2D</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">components_</span> <span class="o">==</span> <span class="n">W2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Explained-Variance-Ratio">Explained Variance Ratio<a class="anchor-link" href="#Explained-Variance-Ratio">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>The ratio indicates the proportion of the dataset's variance lying along each principal component.</li>
<li>Let's take a look at it for our scikit-learn learner:</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(array([0.98698474, 0.01301526]), 1.0)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Choosing-the-Right-Number-of-Dimensions">Choosing the Right Number of Dimensions<a class="anchor-link" href="#Choosing-the-Right-Number-of-Dimensions">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Choose the number of dimensions that add up to a large portion of the variance that lied within the original dataset.<ul>
<li>Example: $&gt;=95\%$</li>
</ul>
</li>
<li>Unless, ofcoures, you are reducing dimensionality to visualize the data.<ul>
<li>In that case you will want to reduce the data down to 2/3 axis.</li>
</ul>
</li>
<li>Let's do it in scikit-learn:</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>PCA(copy=True, iterated_power=&#39;auto&#39;, n_components=None, random_state=None,
    svd_solver=&#39;auto&#39;, tol=0.0, whiten=False)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cumsum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">cumsum</span> <span class="o">&gt;=</span> <span class="o">.</span><span class="mi">95</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">d</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>1</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Then re-run PCA training using $d$.</li>
<li>But there is a much better option, that of specifying a float for <code>n_components</code> as the ratio of variance we want to preserve.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mf">0.95</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_reduced</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="PCA-for-Compression"><code>PCA</code> for Compression<a class="anchor-link" href="#PCA-for-Compression">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>After dimensionality reduction, the training set takes much less space.</li>
<li>It is also possible to decompress the reduced dataset back to $784$ (in the case of MNIST) by applying <strong>the inverse transformation of the PCA projection</strong>.<ul>
<li><strong>This won't give you back the original data since 5% of the variance was lost while compressing</strong>.</li>
<li>But it will likely be close to the original dataset.</li>
</ul>
</li>
<li><strong>The mean squared distance between the original dataset and the decompressed dataset is called the Reconstruction Error</strong>.</li>
<li>Let's do it with scikit-learn:</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">fetch_openml</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;mnist_784&#39;</span><span class="p">,</span> <span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.33</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_test</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>((46900, 784), (23100, 784), (46900,), (23100,))</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">154</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_reduced</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_recovered</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">X_reduced</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;binary&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X_recovered</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;binary&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Following is the equation of the inverse transformation:</li>
</ul>
$$X_{recovered}=X_{d-proj}W_{d}^{T}$$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Randomized-PCA">Randomized PCA<a class="anchor-link" href="#Randomized-PCA">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>We can use a stochastic algorithm called <em>Randomized PCA</em> that quickly finds an approximation of the first $d$ principal components.</li>
<li>Its computational complexity is $O(m \times d^{2})+O(d^3)$ instead of SVD's $O(m \times n^{2})+O(n^3)$.</li>
<li>So it's dramatically faster then SVD when $d &lt;&lt; n$.</li>
<li>Let's use it with <code>scikit-learn</code>:</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">rnd_pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">154</span><span class="p">,</span> <span class="n">svd_solver</span><span class="o">=</span><span class="s1">&#39;randomized&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_reduced</span> <span class="o">=</span> <span class="n">rnd_pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Incremental-PCA">Incremental PCA<a class="anchor-link" href="#Incremental-PCA">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>One problem with the previous implementations of PCA is that they require the whole training data to fit in memory.</li>
<li>Fortunately, <strong>incremental PCA</strong> algorithms have been developed.</li>
<li>They allow us to split the training set in mini-batches and feed them one at a time to the IPCA algorithm.</li>
<li>This is useful when having large training sets or doing online learning.</li>
<li>Let's experiment with incremental PCA using scikit-learn:</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">IncrementalPCA</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">n_batches</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">inc_pca</span> <span class="o">=</span> <span class="n">IncrementalPCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">154</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">X_batch</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">array_split</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">n_batches</span><span class="p">):</span>
    <span class="n">inc_pca</span><span class="o">.</span><span class="n">partial_fit</span><span class="p">(</span><span class="n">X_batch</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_reduced</span> <span class="o">=</span> <span class="n">inc_pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>We can also mimic normal fitting behavior by using the <code>memap</code> class to store our training data:</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Kernel-PCA">Kernel PCA<a class="anchor-link" href="#Kernel-PCA">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Recall that a linear decision boundary in a high-dimensional space corresponds to a non-linear decision boundary in the original low-dimensional space.</li>
<li>It turns out that the "kernel trick" can also be applied to PCA.</li>
<li>Making it possible to perform complex non-linear projections for dimensionality reduction.</li>
<li>It's often <strong>good at preserving clusters of instances after projecting them</strong>.</li>
<li>Let's use kPCA in scikit-learn:</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">KernelPCA</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">rbf_pca</span> <span class="o">=</span> <span class="n">KernelPCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.04</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_reduced</span> <span class="o">=</span> <span class="n">rbf_pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Selecting-a-Kernel-and-Tuning-Hyperparameters">Selecting a Kernel and Tuning Hyperparameters<a class="anchor-link" href="#Selecting-a-Kernel-and-Tuning-Hyperparameters">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><em>Note: Use a GPU</em></li>
</ul>

</div>
</div>
</div>
</div>
 

