{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp reduction\n",
    "# default_cls_lvl 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8. Dimensionality Reduction\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Many ML problems will involve thousands or even millions of features per instance.\n",
    "- Not only all of these features make training extremly slow, but they can also make it much harder for an optimization method to find a good solution.\n",
    "- This problem is often referred to as the **curse of dimensionality**.\n",
    "- In real world problem, it is often possible to reduce the number of features considerably.\n",
    "    - Turning an intractable problem into a tractable one.\n",
    "- The goal is to remove the maximum number of features while minimizing information loss that relates to a specific task\n",
    "    - Task example â€” Classifying MNIST digits.\n",
    "- Reducing dimensionality does cause some information loss.\n",
    "- It also makes your pipeline a bit more complex and thus harder to maintain.\n",
    "- Dimensionality reduction is usually conducted to **speed up training**.\n",
    "- Dimensionality reduction is also extremly useful for data visualization.\n",
    "    - Taking it down to 2/3 dimensions for your data set will allow you visualize it in a 2/3D space.\n",
    "- DataViz is also important to communicate your findings to people who are not data scientists.\n",
    "    - In Particular, decision makers who will use your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this chapter we will:\n",
    "    - Discuss the curse of dimenstionality.\n",
    "    - Get a sense of what goes on in a high-dimenstional space.\n",
    "    - Consider the main two approaches to dimensionality reduction:\n",
    "        - Projection\n",
    "        - Manifold Learning\n",
    "    - Go through 3 popular dimensionality reduction techniques:\n",
    "        - PCA\n",
    "        - Kernel PCA\n",
    "        - LLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Curse of Dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We are so used to living in three dimensions\n",
    "    - 4 if you consider time, and a few more if you are a string theorist.\n",
    "- It turns out that many things behave very differently in high-dimensional spaces.\n",
    "- If you pick a random point in a unit square, it will have ~0.4% chance of being located at <0.001 from a border.\n",
    "- But in a 1,000-dimensional hyper-cube the probability is >99.999999%.\n",
    "    - Most points in a high-dimensional space are very close to the border.\n",
    "- Same goes to distances betweeen points, If you pick two random points in a lower dimensional space, they will be closer in comparison to picking them from a high-dimensional space.\n",
    "- **There is just plenty of space in a high-dimensional one!**\n",
    "- High-dimensional datasets are at risk of being too sparse.\n",
    "- The most dimensions a dataset has, the more risk it is to overfit it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Approaches to Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In most real-world problems, training instances are not spread out uniformly across the dimensions.\n",
    "    - Many features are almost constant, while others are highly correlated.\n",
    "- As a result, all training instances like close to a much-lower dimensional **subspace** of the high-dimensional space.\n",
    "- Here is an example of that:\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img style=\"width:50%\" src=\"static/imgs/subspace_projection.png\" />\n",
    "</div>\n",
    "\n",
    "- If we perpenducarly project every training instance into the subspace, we get a new 2D dataset represented as follows:\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img style=\"width:50%\" src=\"static/imgs/2d_projection.png\" />\n",
    "</div>\n",
    "\n",
    "- However, projection is not always to best approach to dimensionality reduction.\n",
    "    - In many case the subspace may twist & turn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manifold Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A 2D manifold is a 2D shape that can be bent & twisted in a higher-dimensional space.\n",
    "- More generally, a d-dimensional manifold is part of an n-dimensional space (where d < n), that locally resembles a d-dimensional hyperplace.\n",
    "- Many dimensionality reduction algorithms work by modeling the manifold on which the training instances lie, this is called **Manifold Learning**.\n",
    "    - It relies on the *manifold assumption*, also called the *manifold hypothesis*.\n",
    "        - Which holds that most real world high-dimensional datasets lie close to a much lower-dimensional manifold.\n",
    "            - **This assumption is very often empirically observed**.\n",
    "- Thought experiment\n",
    "    - If you were to generate random images on a 28x28 grid, only a very small fraction of them would look like handwritten digits.\n",
    "    - In other words, the degrees of freedom available to you if you were to create a digit image are very low compared to the degree of freedom you have when you want to create any image you want (random).\n",
    "    - **These constraints tend to squeeze the dataset into a lower-dimensional manifold**.\n",
    "- An implicit additional assumption is that the task at hand (being regression or classification) would be much easier if conducted on the lower dimensional manifold space.\n",
    "    - This assumption does not always hold.\n",
    "    - Examples to follow:\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img style=\"width:50%\" src=\"static/imgs/manifold_classification.png\" />\n",
    "</div>\n",
    "\n",
    "- In short, reducing the dimensionality of your dataset will speed up training, but it doesn't guarantee a simpler solution.\n",
    "    - It all depends on the dataset and the task at hand.\n",
    "- Now we will go through some of the most popular dimensionality reduction algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Principal Component Analysis is by far the most popular dimensionality reduction algorithm.\n",
    "- First, **It identifies the hyperplane that lies closest to the data**.\n",
    "- Then, **It projects the data into it**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preserving the Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We want to choose a hyperplace that most preserves tha variance within the data, following is attempted projections for 3 chosen hyperplanes (1D axis):\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img style=\"width:66%\" src=\"static/imgs/2D_variance_projection.png\" />\n",
    "</div>\n",
    "\n",
    "- It seems reasonable to select the axis that preserves the maximum amount of variance.\n",
    "    - As it will most likely lose less information than other projections.\n",
    "- Another way of looking at it is by choosing the solid line axis, we are minimizing the mean squared distance between the original points and their projections into the chosen axis.\n",
    "    - This is the rather simple idea behind PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principle Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PCA identifies the axis that accounts for the largest amount of variance in the training set.\n",
    "- It also finds a second axis, orthogonal to the first one, that accounts for the largest amount of remaining variance.\n",
    "- If we're considering a higher-dimensional dataset, PCA would also find a third axis, and a fourth, and a fifth, and so on...\n",
    "    - As many axes as the number of dimensions in the dataset.\n",
    "- The ith axis is called the ith **principal component** of the data.\n",
    "- So how can you find the principal components of a training set?\n",
    "- There is a standard matrix vectorization technique called *Singular Value Decomposition (SVD)*\n",
    "    - It can decompose the training set $X$ into $X=U \\Sigma V^T$\n",
    "    - $V$ contains the unit vectors that define all the principal components that we are looking for:\n",
    "    \n",
    "$$V=\n",
    "  \\begin{pmatrix}\n",
    "    \\vert & \\vert & \\dots & \\vert \\\\\n",
    "    c_1 & c_2 & \\dots & c_n \\\\\n",
    "    \\vert & \\vert & \\dots & \\vert \\\\\n",
    "  \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "- let's extract the principal components of a dataset using numpy's `svd` implementation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's start by generating some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100,), (100,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.linspace(start=-1., stop=1., num=100)\n",
    "y = X + np.random.normal(size=100)/7.\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X, y, c='blue')\n",
    "plt.xlabel('$X_1$')\n",
    "plt.ylabel('$X_2$')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.concatenate((X[..., None], y[..., None]), axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_centered = X - X.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, s, Vt = np.linalg.svd(a=X_centered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = Vt.T[:, 0]\n",
    "c2 = Vt.T[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.68687442, 0.72677612]), array([-0.72677612,  0.68687442]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1, c2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- These two 2D points represent the unit vector points (origin at (0,0)) corresponding to the 2 principal components (axes that preserve variance).\n",
    "- PCA assumes that the dataset is centered around the origin, but scikit-learn implementation takes care of centering the data for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projecting down to $d$ Dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Once you have identified all the principal components, you can reduce the dimensionality of the dataset down to $d$ dimensions by projecting it onto the hyperplane defined by the first $d$ principal components.\n",
    "- Selecting this hyperplane ensures that the projection will preserve as much variance as possible.\n",
    "- To Project the training set into the hyperplane and obtain a reduced dataset $X_{d-proj}$ of dimensionality $d$:\n",
    "    - Compute the matrix multiplication of the training set matrix $X$ by the matrix $W_{d}$ \n",
    "        - $W_{d}$ is the matrix containing the first $d$ columns of $V$ representing the principal components.\n",
    "\n",
    "$$X_{d-proj}=XW_d$$\n",
    "\n",
    "- Let's do it in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = Vt.T[:, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2D = X_centered.dot(W2)\n",
    "X2D.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2D = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(np.abs(pca.components_) == np.abs(W2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explained Variance Ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The ratio indicates the proportion of the dataset's variance lying along each principal component.\n",
    "- Let's take a look at it for our scikit-learn learner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.98079986, 0.01920014]), 1.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_, np.sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the Right Number of Dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Choose the number of dimensions that add up to a large portion of the variance that lied within the original dataset.\n",
    "    - Example: $>=95\\%$\n",
    "- Unless, ofcoures, you are reducing dimensionality to visualize the data.\n",
    "    - In that case you will want to reduce the data down to 2/3 axis.\n",
    "- Let's do it in scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumsum = np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.argmax(cumsum >= .95) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Then re-run PCA training using $d$.\n",
    "- But there is a much better option, that of specifying a float for `n_components` as the ratio of variance we want to preserve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `PCA` for Compression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After dimensionality reduction, the training set takes much less space.\n",
    "- It is also possible to decompress the reduced dataset back to $784$ (in the case of MNIST) by applying **the inverse transformation of the PCA projection**.\n",
    "    - **This won't give you back the original data since 5% of the variance was lost while compressing**.\n",
    "    - But it will likely be close to the original dataset.\n",
    "- **The mean squared distance between the original dataset and the decompressed dataset is called the Reconstruction Error**.\n",
    "- Let's do it with scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.fetch_openml(name='mnist_784', return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((46900, 784), (23100, 784), (46900,), (23100,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=154)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_recovered = pca.inverse_transform(X_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0].reshape(28, 28), cmap='binary')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_recovered[0].reshape(28, 28), cmap='binary')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Following is the equation of the inverse transformation:\n",
    "\n",
    "$$X_{recovered}=X_{d-proj}W_{d}^{T}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can use a stochastic algorithm called *Randomized PCA* that quickly finds an approximation of the first $d$ principal components.\n",
    "- Its computational complexity is $O(m \\times d^{2})+O(d^3)$ instead of SVD's $O(m \\times n^{2})+O(n^3)$.\n",
    "- So it's dramatically faster then SVD when $d << n$.\n",
    "- Let's use it with `scikit-learn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_pca = PCA(n_components=154, svd_solver='randomized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = rnd_pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incremental PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- One problem with the previous implementations of PCA is that they require the whole training data to fit in memory.\n",
    "- Fortunately, **incremental PCA** algorithms have been developed.\n",
    "- They allow us to split the training set in mini-batches and feed them one at a time to the IPCA algorithm.\n",
    "- This is useful when having large training sets or doing online learning.\n",
    "- Let's experiment with incremental PCA using scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches = 100\n",
    "inc_pca = IncrementalPCA(n_components=154)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for X_batch in np.array_split(X_train, n_batches):\n",
    "    inc_pca.partial_fit(X_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = inc_pca.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can also mimic normal fitting behavior by using the `memap` class to store our training data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recall that a linear decision boundary in a high-dimensional space corresponds to a non-linear decision boundary in the original low-dimensional space.\n",
    "- It turns out that the \"kernel trick\" can also be applied to PCA.\n",
    "- Making it possible to perform complex non-linear projections for dimensionality reduction.\n",
    "- It's often **good at preserving clusters of instances after projecting them**.\n",
    "- Let's use kPCA in scikit-learn:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First we create a swiss roll:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, _ = datasets.make_swiss_roll(n_samples=1000, noise=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_pca = KernelPCA(n_components=2, kernel='rbf', gamma=0.04, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = rbf_pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting a Kernel and Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Note: Use a GPU*\n",
    "- As kPCA is an unsupervised learning algorithm, there is no obvious performance measure to help you select the best kernel and hyper-parameter values.\n",
    "- That said, dimensionality reduction is often a pre-processing step for a supervised learning task.\n",
    "- So you can use grid search to select the kernel and hyper-parameters that lead to the best performance on the end task.\n",
    "- The following scikit-learn example create a two step pipeline:\n",
    "    - First reducing the dimensionality to 2 dimensions using kPCA.\n",
    "    - Then Applying logistic regression for classification.\n",
    "- Then we use `GridSearchCV` to find the best **kernel** and **gamma** value for kPCA in order to get the best classification accuracy at the end of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([\n",
    "    ('kpca', KernelPCA(n_components=2)),\n",
    "    ('log_reg', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{\n",
    "    \"kpca__gamma\": np.linspace(0.03, 0.05, 5),\n",
    "    \"kpca__kernel\": [\"rbf\", \"sigmoid\"]\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(clf, param_grid, cv=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('kpca',\n",
       "                                        KernelPCA(alpha=1.0, coef0=1,\n",
       "                                                  copy_X=True, degree=3,\n",
       "                                                  eigen_solver='auto',\n",
       "                                                  fit_inverse_transform=False,\n",
       "                                                  gamma=None, kernel='linear',\n",
       "                                                  kernel_params=None,\n",
       "                                                  max_iter=None, n_components=2,\n",
       "                                                  n_jobs=None,\n",
       "                                                  random_state=None,\n",
       "                                                  remove_zero_eig=False,\n",
       "                                                  tol=0)),\n",
       "                                       ('log_reg',\n",
       "                                        LogisticReg...\n",
       "                                                           l1_ratio=None,\n",
       "                                                           max_iter=100,\n",
       "                                                           multi_class='warn',\n",
       "                                                           n_jobs=None,\n",
       "                                                           penalty='l2',\n",
       "                                                           random_state=None,\n",
       "                                                           solver='warn',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid=[{'kpca__gamma': array([0.03 , 0.035, 0.04 , 0.045, 0.05 ]),\n",
       "                          'kpca__kernel': ['rbf', 'sigmoid']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train[:10000], y_train[:10000])  # not enough compute for all training all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kpca__gamma': 0.03, 'kpca__kernel': 'rbf'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Another approach, entirely unsupervised, is to select the kernel and hyper-parameters that **yield the lowest reconstruction error**.\n",
    "- Let's visualize the steps we take with kernel-based dimensionality reduction:\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img style=\"width:50%\" src=\"static/imgs/reconstruction_vis.png\" />\n",
    "</div>\n",
    "\n",
    "- Notice that when we invert our final transformation, we get instance on the infinite feature space and not the original space.\n",
    "- Since the feature space is infinite, we cannot compute the reconstruction loss. \n",
    "- But it's possible to find a point in the original space that map close to the reconstructed point, this point is called the reconstructed **pre-image**.\n",
    "- Once you have the pre-image, you can measure its squared distance to the original instance.\n",
    "- In terms of **how to perform the reconstruction**, You can train a supervised learning algorithm to find a mapping between the original dataset and the reduced data.\n",
    "- scikit-learn can do it for you with the `fit_inverse_transform` hyper-parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_pca = KernelPCA(n_components=2, kernel='rbf', gamma=0.0433, fit_inverse_transform=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = rbf_pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_preimage = rbf_pca.inverse_transform(X_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.494723308154935"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(X, X_preimage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can you grid search to find the hyper-parameters that minimize this error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Locally Linear Embedding is a powerful non-linear dimensionality reduction technique.\n",
    "- It's a manifold learning technique that doesn't rely on projections like the previous algorithms do.\n",
    "- LLE works by first measuring how each instance relates to its neighbors\n",
    "- Then it looks for low-dimensional representation of the training set where each local relationship is best preserved.\n",
    "- Let's use it with scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import LocallyLinearEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "lle = LocallyLinearEmbedding(n_components=2, n_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = lle.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The resulting 2D dataset is shown as follows:\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img style=\"width:50%\" src=\"static/imgs/swiss_unroll.png\" />\n",
    "</div>\n",
    "\n",
    "- LLE did a pretty good job at modeling the manifold.\n",
    "- Here is how LLE works:\n",
    "    1. For each training instance $x^{(i)}$, the algorithm identifies its $k$ closest neighbors.\n",
    "    2. The Algorithm tries to reconstruct $x^{(i)}$ as a linear function of these neighbors.\n",
    "    3. It finds $w_{i,j}$ such that it minimizes $J(x^{(i)}, \\sum_{j=1}^{m}w_{i,j}x^{(j)})$.\n",
    "- We can formalize the problem as follows:\n",
    "\n",
    "$$\\hat{W}=argmin_{W}\\sum_{i=1}^{m}(x^{(i)} - \\sum_{j=1}^{m}w_{i,j}x^{(j)}))^2$$\n",
    "\n",
    "- Such that the sum of each instance weights is $1$.\n",
    "- After this step, **$\\hat{W}$ encodes the local linear relationships between the training instances**.\n",
    "- The second step is to map the training instances into a d-dimensional space (where $d<n$) **while preserving these local relationships as much as possible**.\n",
    "- if $z^{(i)}$ is the image of $x^{(i)}$ in this d-dimensional space, then we want to minimize $J(z^{(i)}, \\sum_{j=1}^{m}\\hat{w}_{i,j}z^{(j)})$.\n",
    "- This leads to the following unconstrained optimization problem:\n",
    "\n",
    "$$\\hat{Z}=argmin_{Z}\\sum_{i=1}^{m}(z^{(i)} - \\sum_{j=1}^{m}\\hat{w}_{i,j}z^{(j)}))^2$$\n",
    "\n",
    "- Scikit-learn LLE implementation has the following computational complexity:\n",
    "    - $O(m log(m) n log(k))$ for finding the k nearest neighbors.\n",
    "    - $O(mnk^3)$ for optimizing the weights.\n",
    "    - $O(dm^2)$ for constructing the low-dimensional representations.\n",
    "        - The $m^2$ makes the algorithm scales very poorly to large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Dimensionality Reduction Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here are some of the most popular ones\n",
    "    - [Random projections](https://scikit-learn.org/stable/modules/random_projection.html).\n",
    "    - Multidimensional scaling.\n",
    "    - IsoMap\n",
    "    - t-Distributed Stochastic Neighbor Embedding (t-SNE)\n",
    "    - Linear Discriminant Analysis (LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. What are the main motivations for reducing a Dataset's dimensionality? What are the main Drawbacks?**\n",
    "\n",
    "- Motivations: So you can visualize the data in 2D/3D spaces. Also We want to reduce the dimensionality of big datasets that we suspect have static or very noisy features, so reduction will be a preprocessing step to then train the reduced dataset for the final task (faster training).\n",
    "- Drawbacks: By reducing the dimensionality of the dataset, we typically lose some useful information in the process even though we try to preserve as much as possible. So the resulting trained classifier will typically be weaker than a classifier trained on the original dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. What is the curse of dimensionality?**\n",
    "\n",
    "- As we increase the number of dimensions (or features) the average distance between any two instance tend to increase as well, in other words, in a high-dimensional spaces, instances tend to sit on the edges of the space. This leads to training problems since no clusters are apparent in a space filled with void (in the case of a classification task). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Once a Dataset's dimensionality has been reduced, is it possible to reverse the operation? If so, how? If not, why?**\n",
    "\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
